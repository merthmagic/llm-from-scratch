{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPLM\n",
    "Neural Probabilistic Language Model\n",
    "\n",
    "神经概率语言模型\n",
    "\n",
    "<img src=\"attachments/nplm-structure.jpg\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建语料库\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'讨厌': 0, '爱': 1, '喜欢': 2, '我': 3, '爸爸': 4, '挨打': 5, '玩具': 6}\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"我 喜欢 玩具\",\n",
    "    \"我 爱 爸爸\",\n",
    "    \"我 讨厌 挨打\"\n",
    "] # 这里的中文用了空格来简化分词lol\n",
    "\n",
    "word_list = list(set(' '.join(sentences).split()))\n",
    "word_to_idx = {word:idx for idx,word in enumerate(word_list)}\n",
    "voc_size = len(word_list)\n",
    "idx_to_word =  {idx:word for idx,word in enumerate(word_list)}\n",
    "\n",
    "print(word_to_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入批处理数据:tensor([[3, 1],\n",
      "        [3, 2]])\n",
      "输入批处理数据对应的原始词:[['我', '爱'], ['我', '喜欢']]\n",
      "目标批处理数据:tensor([4, 6])\n",
      "目标批处理数据对应的原始词:['爸爸', '玩具']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "def make_batch():\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    selected_sentences = random.sample(sentences,batch_size)\n",
    "    \n",
    "    for sentence in selected_sentences:\n",
    "        words = sentence.split()\n",
    "        input = [word_to_idx[n] for n in words[:-1]] # 最后一个词以外的词作为输入\n",
    "        target = word_to_idx[words[-1]] # 最后一个词作为目标\n",
    "        input_batch.append(input)\n",
    "        target_batch.append(target)\n",
    "    \n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    target_batch = torch.LongTensor(target_batch)\n",
    "    \n",
    "    return input_batch,target_batch\n",
    "\n",
    "input_batch,target_batch = make_batch()\n",
    "print(f\"输入批处理数据:{input_batch}\")\n",
    "\n",
    "\n",
    "input_words = []\n",
    "for input_idx in input_batch:\n",
    "    input_words.append([idx_to_word[idx.item()] for idx in input_idx])\n",
    "    # for idx in input_idx:\n",
    "    #     input_words.append([idx_to_word[idx.item()]])\n",
    "        \n",
    "print(f\"输入批处理数据对应的原始词:{input_words}\")\n",
    "print(f\"目标批处理数据:{target_batch}\")\n",
    "\n",
    "target_words = [idx_to_word[idx.item()] for idx in target_batch]\n",
    "print(f\"目标批处理数据对应的原始词:{target_words}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
